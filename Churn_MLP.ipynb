{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdIIKDedDOpucPECMZcCw8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandobb1411/MLP_Churn/blob/main/Churn_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checar github para melhores explicações sobre o codigo.\n"
      ],
      "metadata": {
        "id": "4W2kRax2_cih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4ct63PMQFeB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "from tensorflow.keras import datasets, layers, models, Sequential, optimizers, regularizers\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "WX6_wom6EFP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/dataset.csv', delimiter=',')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "BiTBUBvjAi8S",
        "outputId": "78bc7bee-ff87-4e76-fd05-9726353d31e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CustomerId           Surname  CreditScore Geography  Gender  Age  \\\n",
              "0       15647572            Greece          504     Spain    Male   34   \n",
              "1       15797692           Volkova          659    France  Female   33   \n",
              "2       15713559  Onyemauchechukwu          473   Germany  Female   32   \n",
              "3       15595067            Zhirov          637     Spain  Female   40   \n",
              "4       15810167             Scott          657     Spain    Male   75   \n",
              "...          ...               ...          ...       ...     ...  ...   \n",
              "8995    15770214            Bryant          754    France  Female   27   \n",
              "8996    15720134          Reynolds          709   Germany    Male   30   \n",
              "8997    15700549           Alvares          721    France    Male   54   \n",
              "8998    15704081           Findlay          595   Germany    Male   30   \n",
              "8999    15767729             Smith          646     Spain    Male   25   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          0   54980.81              1          1               1   \n",
              "1          7   89939.62              1          1               0   \n",
              "2          5  146602.25              2          1               1   \n",
              "3          6       0.00              2          1               1   \n",
              "4          7  126273.95              1          0               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "8995       7       0.00              2          1               0   \n",
              "8996       9  115479.48              2          1               1   \n",
              "8997       5       0.00              2          1               1   \n",
              "8998       9  130682.11              2          1               1   \n",
              "8999       5  182876.88              2          1               1   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           136909.88       0  \n",
              "1           136540.09       0  \n",
              "2            72946.95       0  \n",
              "3           181610.60       0  \n",
              "4            91673.60       0  \n",
              "...               ...     ...  \n",
              "8995        144134.64       0  \n",
              "8996        134732.99       0  \n",
              "8997          4493.12       0  \n",
              "8998         57862.88       0  \n",
              "8999         42537.59       1  \n",
              "\n",
              "[9000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acb138ce-1142-41b4-b3ee-75339c6e3ac6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15647572</td>\n",
              "      <td>Greece</td>\n",
              "      <td>504</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>54980.81</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>136909.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15797692</td>\n",
              "      <td>Volkova</td>\n",
              "      <td>659</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>33</td>\n",
              "      <td>7</td>\n",
              "      <td>89939.62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>136540.09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15713559</td>\n",
              "      <td>Onyemauchechukwu</td>\n",
              "      <td>473</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>146602.25</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72946.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15595067</td>\n",
              "      <td>Zhirov</td>\n",
              "      <td>637</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>181610.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15810167</td>\n",
              "      <td>Scott</td>\n",
              "      <td>657</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>126273.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>91673.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>15770214</td>\n",
              "      <td>Bryant</td>\n",
              "      <td>754</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144134.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>15720134</td>\n",
              "      <td>Reynolds</td>\n",
              "      <td>709</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>115479.48</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>134732.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>15700549</td>\n",
              "      <td>Alvares</td>\n",
              "      <td>721</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>54</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4493.12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>15704081</td>\n",
              "      <td>Findlay</td>\n",
              "      <td>595</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>130682.11</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57862.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>15767729</td>\n",
              "      <td>Smith</td>\n",
              "      <td>646</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>182876.88</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42537.59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acb138ce-1142-41b4-b3ee-75339c6e3ac6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acb138ce-1142-41b4-b3ee-75339c6e3ac6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acb138ce-1142-41b4-b3ee-75339c6e3ac6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como as informações são strings, para conseguirmos preve-las vamos anexar cada classe a um int:\n",
        "Spain:0\n",
        "France:1\n",
        "Germany:2\n",
        "\n",
        "Male:0\n",
        "Female:2"
      ],
      "metadata": {
        "id": "YzGTt2USEJ0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_string_type_columns(customer_dataset_df):\n",
        "  customer_dataset_df.loc[customer_dataset_df['Geography']== 'Spain', 'Geography'] = 0\n",
        "  customer_dataset_df.loc[customer_dataset_df['Geography']== 'France', 'Geography'] = 1\n",
        "  customer_dataset_df.loc[customer_dataset_df['Geography']== 'Germany', 'Geography'] = 2\n",
        "  customer_dataset_df.loc[customer_dataset_df['Gender']== 'Male', 'Gender'] = 0\n",
        "  customer_dataset_df.loc[customer_dataset_df['Gender']== 'Female', 'Gender'] = 1\n",
        "  return customer_dataset_df"
      ],
      "metadata": {
        "id": "yHKyiCUaEItp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= handle_string_type_columns(df)"
      ],
      "metadata": {
        "id": "6fZW8QFJEhtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "agora não temos mais string em nosso dataset"
      ],
      "metadata": {
        "id": "aj2PI4yAEoNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "WG_5KZx6EnPB",
        "outputId": "6b9d07ee-d9f0-4115-c182-05b7a3993397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CustomerId           Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
              "0       15647572            Greece          504         0      0   34       0   \n",
              "1       15797692           Volkova          659         1      1   33       7   \n",
              "2       15713559  Onyemauchechukwu          473         2      1   32       5   \n",
              "3       15595067            Zhirov          637         0      1   40       6   \n",
              "4       15810167             Scott          657         0      0   75       7   \n",
              "...          ...               ...          ...       ...    ...  ...     ...   \n",
              "8995    15770214            Bryant          754         1      1   27       7   \n",
              "8996    15720134          Reynolds          709         2      0   30       9   \n",
              "8997    15700549           Alvares          721         1      0   54       5   \n",
              "8998    15704081           Findlay          595         2      0   30       9   \n",
              "8999    15767729             Smith          646         0      0   25       5   \n",
              "\n",
              "        Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
              "0      54980.81              1          1               1        136909.88   \n",
              "1      89939.62              1          1               0        136540.09   \n",
              "2     146602.25              2          1               1         72946.95   \n",
              "3          0.00              2          1               1        181610.60   \n",
              "4     126273.95              1          0               1         91673.60   \n",
              "...         ...            ...        ...             ...              ...   \n",
              "8995       0.00              2          1               0        144134.64   \n",
              "8996  115479.48              2          1               1        134732.99   \n",
              "8997       0.00              2          1               1          4493.12   \n",
              "8998  130682.11              2          1               1         57862.88   \n",
              "8999  182876.88              2          1               1         42537.59   \n",
              "\n",
              "      Exited  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "8995       0  \n",
              "8996       0  \n",
              "8997       0  \n",
              "8998       0  \n",
              "8999       1  \n",
              "\n",
              "[9000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dac804b0-dd93-46ba-b154-b6787528a926\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15647572</td>\n",
              "      <td>Greece</td>\n",
              "      <td>504</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>54980.81</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>136909.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15797692</td>\n",
              "      <td>Volkova</td>\n",
              "      <td>659</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>7</td>\n",
              "      <td>89939.62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>136540.09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15713559</td>\n",
              "      <td>Onyemauchechukwu</td>\n",
              "      <td>473</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>146602.25</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72946.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15595067</td>\n",
              "      <td>Zhirov</td>\n",
              "      <td>637</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>181610.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15810167</td>\n",
              "      <td>Scott</td>\n",
              "      <td>657</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>126273.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>91673.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>15770214</td>\n",
              "      <td>Bryant</td>\n",
              "      <td>754</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144134.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>15720134</td>\n",
              "      <td>Reynolds</td>\n",
              "      <td>709</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>115479.48</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>134732.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>15700549</td>\n",
              "      <td>Alvares</td>\n",
              "      <td>721</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4493.12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>15704081</td>\n",
              "      <td>Findlay</td>\n",
              "      <td>595</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>130682.11</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57862.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>15767729</td>\n",
              "      <td>Smith</td>\n",
              "      <td>646</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>182876.88</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42537.59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dac804b0-dd93-46ba-b154-b6787528a926')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dac804b0-dd93-46ba-b154-b6787528a926 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dac804b0-dd93-46ba-b154-b6787528a926');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nos livramos das colunas que não vamos usar para o treinamento"
      ],
      "metadata": {
        "id": "gTE5OQouEy15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(columns=['CustomerId', 'Surname'])"
      ],
      "metadata": {
        "id": "df2o4i70EstR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vou aplicar MinMax nas colunas que tem grandes quantidades de numeros continuos, o EstimatedSalary e uma delas"
      ],
      "metadata": {
        "id": "Q1lydckyE8fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "RP3iZJxhFIIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['CreditScore']]= scaler.fit_transform(df[['CreditScore']])"
      ],
      "metadata": {
        "id": "_WVk7_u1FKTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.columns]= scaler.fit_transform(df[df.columns])"
      ],
      "metadata": {
        "id": "tIL401zLFL6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DNGlZx-1FVLo",
        "outputId": "a8f7c908-bb75-4b38-8f5d-ab7c055a517b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Geography  Gender       Age  Tenure   Balance  \\\n",
              "0           0.308        0.0     0.0  0.216216     0.0  0.219136   \n",
              "1           0.618        0.5     1.0  0.202703     0.7  0.358471   \n",
              "2           0.246        1.0     1.0  0.189189     0.5  0.584310   \n",
              "3           0.574        0.0     1.0  0.297297     0.6  0.000000   \n",
              "4           0.614        0.0     0.0  0.770270     0.7  0.503288   \n",
              "...           ...        ...     ...       ...     ...       ...   \n",
              "8995        0.808        0.5     1.0  0.121622     0.7  0.000000   \n",
              "8996        0.718        1.0     0.0  0.162162     0.9  0.460264   \n",
              "8997        0.742        0.5     0.0  0.486486     0.5  0.000000   \n",
              "8998        0.490        1.0     0.0  0.162162     0.9  0.520857   \n",
              "8999        0.592        0.0     0.0  0.094595     0.5  0.728889   \n",
              "\n",
              "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
              "0          0.000000        1.0             1.0         0.684433     0.0  \n",
              "1          0.000000        1.0             0.0         0.682583     0.0  \n",
              "2          0.333333        1.0             1.0         0.364462     0.0  \n",
              "3          0.333333        1.0             1.0         0.908046     0.0  \n",
              "4          0.000000        0.0             1.0         0.458141     0.0  \n",
              "...             ...        ...             ...              ...     ...  \n",
              "8995       0.333333        1.0             0.0         0.720574     0.0  \n",
              "8996       0.333333        1.0             1.0         0.673543     0.0  \n",
              "8997       0.333333        1.0             1.0         0.022026     0.0  \n",
              "8998       0.333333        1.0             1.0         0.289005     0.0  \n",
              "8999       0.333333        1.0             1.0         0.212341     1.0  \n",
              "\n",
              "[9000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0343ae4-7803-42fc-b352-c93e323d4528\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.219136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.684433</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.618</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.202703</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.358471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.682583</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.246</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.584310</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.364462</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908046</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.503288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458141</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>0.808</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.121622</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.720574</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>0.718</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.460264</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.673543</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>0.742</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.022026</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>0.490</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.520857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.289005</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>0.592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094595</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.728889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.212341</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0343ae4-7803-42fc-b352-c93e323d4528')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0343ae4-7803-42fc-b352-c93e323d4528 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0343ae4-7803-42fc-b352-c93e323d4528');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos dividir o dataset para o treniamento, a divisão e feita em test, train e val"
      ],
      "metadata": {
        "id": "72yLfz-FFZJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_df= df[\"Exited\"]"
      ],
      "metadata": {
        "id": "R9WAoIDkFlFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df= df.drop(columns=['Exited'])"
      ],
      "metadata": {
        "id": "4mMOnAsSFo1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_df, Y_df, test_size=0.2, random_state=7)"
      ],
      "metadata": {
        "id": "bCwvp9nxFrVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o keras (suporte para redes neurais) não aceita o formato de CSV, teremos que transformar o dataset em um array do numpy (que seria o formato aceito)"
      ],
      "metadata": {
        "id": "JcyYWBHxFzrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_numpy= X_train.to_numpy()\n",
        "y_train_numpy= y_train.to_numpy()\n",
        "X_test_numpy= X_test.to_numpy()\n",
        "y_test_numpy= y_test.to_numpy()"
      ],
      "metadata": {
        "id": "DYDfU56jFxsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa conversão faz todos os valores ficarem como obj, transformar para float haha"
      ],
      "metadata": {
        "id": "yOv7zmsjF_Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_numpy = np.asarray(X_train_numpy).astype('float32')\n",
        "y_train_numpy = np.asarray(y_train_numpy).astype('float32')\n",
        "\n",
        "X_test_numpy = np.asarray(X_test_numpy).astype('float32')\n",
        "y_test_numpy = np.asarray(y_test_numpy).astype('float32')"
      ],
      "metadata": {
        "id": "T6jeB5pvF-Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construindo um modelo sequencial no tensor flow com o suporte do keras"
      ],
      "metadata": {
        "id": "wDmnBkdeGHLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função que recebe as metricas precision e recall, faz um calculo que calcula o score pra validar se o numero esta bom ou não, jeito de ver se nosso modelo ta deboas"
      ],
      "metadata": {
        "id": "Jf_asZOsHrJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TREINAMENTO"
      ],
      "metadata": {
        "id": "udGNUKPmGYIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential()"
      ],
      "metadata": {
        "id": "AyvcvC52GZu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construindo as layers"
      ],
      "metadata": {
        "id": "iUzf9qFMGbxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "model.add(tf.keras.Input(shape=(10,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "zkp_74pDGes4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= optimizers.Adam(lr=0.01),loss='binary_crossentropy',metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5), tf.keras.metrics.BinaryCrossentropy(), tf.keras.metrics.Precision(thresholds=0.5), tf.keras.metrics.Recall(thresholds=0.5)] )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4D-WYK3G1ag",
        "outputId": "6f68ab5d-ab3e-4f76-bcb3-776a490fb38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfim, a linha fit, TREINAR"
      ],
      "metadata": {
        "id": "auI_deSFG8IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x= X_train_numpy, y=y_train_numpy, batch_size=BATCH_SIZE, epochs=80, verbose=2, validation_data= (X_test_numpy,y_test_numpy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE5mYSj0G6MX",
        "outputId": "86bacdd5-f2a7-4d05-ebc5-0d5da676fbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "225/225 - 2s - loss: 0.4738 - binary_accuracy: 0.7904 - binary_crossentropy: 0.4738 - precision: 0.2000 - recall: 0.0075 - val_loss: 0.4353 - val_binary_accuracy: 0.8028 - val_binary_crossentropy: 0.4353 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 2s/epoch - 11ms/step\n",
            "Epoch 2/80\n",
            "225/225 - 1s - loss: 0.4066 - binary_accuracy: 0.8160 - binary_crossentropy: 0.4066 - precision: 0.6951 - recall: 0.1822 - val_loss: 0.4074 - val_binary_accuracy: 0.8272 - val_binary_crossentropy: 0.4074 - val_precision: 0.5632 - val_recall: 0.5521 - 615ms/epoch - 3ms/step\n",
            "Epoch 3/80\n",
            "225/225 - 1s - loss: 0.3681 - binary_accuracy: 0.8478 - binary_crossentropy: 0.3681 - precision: 0.7468 - recall: 0.3896 - val_loss: 0.3664 - val_binary_accuracy: 0.8600 - val_binary_crossentropy: 0.3664 - val_precision: 0.8160 - val_recall: 0.3746 - 598ms/epoch - 3ms/step\n",
            "Epoch 4/80\n",
            "225/225 - 1s - loss: 0.3627 - binary_accuracy: 0.8499 - binary_crossentropy: 0.3627 - precision: 0.7503 - recall: 0.4011 - val_loss: 0.3679 - val_binary_accuracy: 0.8650 - val_binary_crossentropy: 0.3679 - val_precision: 0.7393 - val_recall: 0.4873 - 603ms/epoch - 3ms/step\n",
            "Epoch 5/80\n",
            "225/225 - 1s - loss: 0.3592 - binary_accuracy: 0.8536 - binary_crossentropy: 0.3592 - precision: 0.7698 - recall: 0.4079 - val_loss: 0.3705 - val_binary_accuracy: 0.8594 - val_binary_crossentropy: 0.3705 - val_precision: 0.8228 - val_recall: 0.3662 - 543ms/epoch - 2ms/step\n",
            "Epoch 6/80\n",
            "225/225 - 1s - loss: 0.3524 - binary_accuracy: 0.8536 - binary_crossentropy: 0.3524 - precision: 0.7784 - recall: 0.3997 - val_loss: 0.3724 - val_binary_accuracy: 0.8578 - val_binary_crossentropy: 0.3724 - val_precision: 0.7463 - val_recall: 0.4225 - 601ms/epoch - 3ms/step\n",
            "Epoch 7/80\n",
            "225/225 - 1s - loss: 0.3485 - binary_accuracy: 0.8564 - binary_crossentropy: 0.3485 - precision: 0.7728 - recall: 0.4241 - val_loss: 0.3529 - val_binary_accuracy: 0.8500 - val_binary_crossentropy: 0.3529 - val_precision: 0.6412 - val_recall: 0.5437 - 616ms/epoch - 3ms/step\n",
            "Epoch 8/80\n",
            "225/225 - 1s - loss: 0.3501 - binary_accuracy: 0.8576 - binary_crossentropy: 0.3501 - precision: 0.7740 - recall: 0.4316 - val_loss: 0.3517 - val_binary_accuracy: 0.8622 - val_binary_crossentropy: 0.3517 - val_precision: 0.7744 - val_recall: 0.4254 - 529ms/epoch - 2ms/step\n",
            "Epoch 9/80\n",
            "225/225 - 1s - loss: 0.3495 - binary_accuracy: 0.8569 - binary_crossentropy: 0.3495 - precision: 0.7451 - recall: 0.4593 - val_loss: 0.3737 - val_binary_accuracy: 0.8406 - val_binary_crossentropy: 0.3737 - val_precision: 0.5955 - val_recall: 0.5972 - 595ms/epoch - 3ms/step\n",
            "Epoch 10/80\n",
            "225/225 - 1s - loss: 0.3480 - binary_accuracy: 0.8574 - binary_crossentropy: 0.3480 - precision: 0.7728 - recall: 0.4309 - val_loss: 0.3663 - val_binary_accuracy: 0.8550 - val_binary_crossentropy: 0.3663 - val_precision: 0.6741 - val_recall: 0.5127 - 521ms/epoch - 2ms/step\n",
            "Epoch 11/80\n",
            "225/225 - 1s - loss: 0.3441 - binary_accuracy: 0.8594 - binary_crossentropy: 0.3441 - precision: 0.7516 - recall: 0.4695 - val_loss: 0.3440 - val_binary_accuracy: 0.8650 - val_binary_crossentropy: 0.3440 - val_precision: 0.7667 - val_recall: 0.4535 - 534ms/epoch - 2ms/step\n",
            "Epoch 12/80\n",
            "225/225 - 1s - loss: 0.3457 - binary_accuracy: 0.8569 - binary_crossentropy: 0.3457 - precision: 0.7648 - recall: 0.4363 - val_loss: 0.3455 - val_binary_accuracy: 0.8650 - val_binary_crossentropy: 0.3455 - val_precision: 0.7295 - val_recall: 0.5014 - 536ms/epoch - 2ms/step\n",
            "Epoch 13/80\n",
            "225/225 - 1s - loss: 0.3456 - binary_accuracy: 0.8582 - binary_crossentropy: 0.3456 - precision: 0.7661 - recall: 0.4438 - val_loss: 0.3708 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3708 - val_precision: 0.8012 - val_recall: 0.3746 - 538ms/epoch - 2ms/step\n",
            "Epoch 14/80\n",
            "225/225 - 1s - loss: 0.3420 - binary_accuracy: 0.8600 - binary_crossentropy: 0.3420 - precision: 0.7861 - recall: 0.4356 - val_loss: 0.3633 - val_binary_accuracy: 0.8544 - val_binary_crossentropy: 0.3633 - val_precision: 0.6598 - val_recall: 0.5408 - 609ms/epoch - 3ms/step\n",
            "Epoch 15/80\n",
            "225/225 - 1s - loss: 0.3444 - binary_accuracy: 0.8557 - binary_crossentropy: 0.3444 - precision: 0.7661 - recall: 0.4262 - val_loss: 0.3475 - val_binary_accuracy: 0.8611 - val_binary_crossentropy: 0.3475 - val_precision: 0.7178 - val_recall: 0.4873 - 540ms/epoch - 2ms/step\n",
            "Epoch 16/80\n",
            "225/225 - 1s - loss: 0.3422 - binary_accuracy: 0.8606 - binary_crossentropy: 0.3422 - precision: 0.7694 - recall: 0.4566 - val_loss: 0.3496 - val_binary_accuracy: 0.8628 - val_binary_crossentropy: 0.3496 - val_precision: 0.7348 - val_recall: 0.4761 - 540ms/epoch - 2ms/step\n",
            "Epoch 17/80\n",
            "225/225 - 1s - loss: 0.3402 - binary_accuracy: 0.8582 - binary_crossentropy: 0.3402 - precision: 0.7525 - recall: 0.4593 - val_loss: 0.3537 - val_binary_accuracy: 0.8639 - val_binary_crossentropy: 0.3537 - val_precision: 0.7331 - val_recall: 0.4873 - 541ms/epoch - 2ms/step\n",
            "Epoch 18/80\n",
            "225/225 - 1s - loss: 0.3396 - binary_accuracy: 0.8608 - binary_crossentropy: 0.3396 - precision: 0.7505 - recall: 0.4810 - val_loss: 0.3507 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3507 - val_precision: 0.7028 - val_recall: 0.4930 - 543ms/epoch - 2ms/step\n",
            "Epoch 19/80\n",
            "225/225 - 1s - loss: 0.3376 - binary_accuracy: 0.8625 - binary_crossentropy: 0.3376 - precision: 0.7800 - recall: 0.4587 - val_loss: 0.3540 - val_binary_accuracy: 0.8550 - val_binary_crossentropy: 0.3540 - val_precision: 0.8052 - val_recall: 0.3493 - 592ms/epoch - 3ms/step\n",
            "Epoch 20/80\n",
            "225/225 - 1s - loss: 0.3390 - binary_accuracy: 0.8593 - binary_crossentropy: 0.3390 - precision: 0.7689 - recall: 0.4485 - val_loss: 0.3467 - val_binary_accuracy: 0.8600 - val_binary_crossentropy: 0.3467 - val_precision: 0.7877 - val_recall: 0.3972 - 609ms/epoch - 3ms/step\n",
            "Epoch 21/80\n",
            "225/225 - 1s - loss: 0.3372 - binary_accuracy: 0.8593 - binary_crossentropy: 0.3372 - precision: 0.7587 - recall: 0.4600 - val_loss: 0.3630 - val_binary_accuracy: 0.8528 - val_binary_crossentropy: 0.3630 - val_precision: 0.6442 - val_recall: 0.5662 - 537ms/epoch - 2ms/step\n",
            "Epoch 22/80\n",
            "225/225 - 1s - loss: 0.3374 - binary_accuracy: 0.8618 - binary_crossentropy: 0.3374 - precision: 0.7806 - recall: 0.4533 - val_loss: 0.3524 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3524 - val_precision: 0.6838 - val_recall: 0.5239 - 596ms/epoch - 3ms/step\n",
            "Epoch 23/80\n",
            "225/225 - 1s - loss: 0.3372 - binary_accuracy: 0.8624 - binary_crossentropy: 0.3372 - precision: 0.7691 - recall: 0.4695 - val_loss: 0.3471 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3471 - val_precision: 0.7988 - val_recall: 0.3803 - 604ms/epoch - 3ms/step\n",
            "Epoch 24/80\n",
            "225/225 - 1s - loss: 0.3351 - binary_accuracy: 0.8615 - binary_crossentropy: 0.3351 - precision: 0.7688 - recall: 0.4641 - val_loss: 0.3472 - val_binary_accuracy: 0.8628 - val_binary_crossentropy: 0.3472 - val_precision: 0.7727 - val_recall: 0.4310 - 514ms/epoch - 2ms/step\n",
            "Epoch 25/80\n",
            "225/225 - 1s - loss: 0.3327 - binary_accuracy: 0.8643 - binary_crossentropy: 0.3327 - precision: 0.7865 - recall: 0.4641 - val_loss: 0.3479 - val_binary_accuracy: 0.8600 - val_binary_crossentropy: 0.3479 - val_precision: 0.7269 - val_recall: 0.4648 - 608ms/epoch - 3ms/step\n",
            "Epoch 26/80\n",
            "225/225 - 1s - loss: 0.3329 - binary_accuracy: 0.8617 - binary_crossentropy: 0.3329 - precision: 0.7791 - recall: 0.4539 - val_loss: 0.3578 - val_binary_accuracy: 0.8622 - val_binary_crossentropy: 0.3578 - val_precision: 0.7149 - val_recall: 0.5014 - 540ms/epoch - 2ms/step\n",
            "Epoch 27/80\n",
            "225/225 - 1s - loss: 0.3345 - binary_accuracy: 0.8637 - binary_crossentropy: 0.3345 - precision: 0.7803 - recall: 0.4668 - val_loss: 0.3456 - val_binary_accuracy: 0.8650 - val_binary_crossentropy: 0.3456 - val_precision: 0.7800 - val_recall: 0.4394 - 605ms/epoch - 3ms/step\n",
            "Epoch 28/80\n",
            "225/225 - 1s - loss: 0.3342 - binary_accuracy: 0.8601 - binary_crossentropy: 0.3342 - precision: 0.7650 - recall: 0.4587 - val_loss: 0.3498 - val_binary_accuracy: 0.8617 - val_binary_crossentropy: 0.3498 - val_precision: 0.7284 - val_recall: 0.4761 - 613ms/epoch - 3ms/step\n",
            "Epoch 29/80\n",
            "225/225 - 1s - loss: 0.3335 - binary_accuracy: 0.8607 - binary_crossentropy: 0.3335 - precision: 0.7826 - recall: 0.4438 - val_loss: 0.3473 - val_binary_accuracy: 0.8622 - val_binary_crossentropy: 0.3473 - val_precision: 0.7610 - val_recall: 0.4394 - 576ms/epoch - 3ms/step\n",
            "Epoch 30/80\n",
            "225/225 - 1s - loss: 0.3336 - binary_accuracy: 0.8624 - binary_crossentropy: 0.3336 - precision: 0.7633 - recall: 0.4763 - val_loss: 0.3533 - val_binary_accuracy: 0.8556 - val_binary_crossentropy: 0.3533 - val_precision: 0.6939 - val_recall: 0.4789 - 549ms/epoch - 2ms/step\n",
            "Epoch 31/80\n",
            "225/225 - 1s - loss: 0.3330 - binary_accuracy: 0.8632 - binary_crossentropy: 0.3330 - precision: 0.7643 - recall: 0.4810 - val_loss: 0.3714 - val_binary_accuracy: 0.8550 - val_binary_crossentropy: 0.3714 - val_precision: 0.6632 - val_recall: 0.5380 - 585ms/epoch - 3ms/step\n",
            "Epoch 32/80\n",
            "225/225 - 1s - loss: 0.3356 - binary_accuracy: 0.8607 - binary_crossentropy: 0.3356 - precision: 0.7697 - recall: 0.4573 - val_loss: 0.3563 - val_binary_accuracy: 0.8594 - val_binary_crossentropy: 0.3563 - val_precision: 0.7024 - val_recall: 0.4986 - 531ms/epoch - 2ms/step\n",
            "Epoch 33/80\n",
            "225/225 - 1s - loss: 0.3351 - binary_accuracy: 0.8611 - binary_crossentropy: 0.3351 - precision: 0.7604 - recall: 0.4709 - val_loss: 0.3584 - val_binary_accuracy: 0.8539 - val_binary_crossentropy: 0.3584 - val_precision: 0.6620 - val_recall: 0.5296 - 530ms/epoch - 2ms/step\n",
            "Epoch 34/80\n",
            "225/225 - 1s - loss: 0.3300 - binary_accuracy: 0.8661 - binary_crossentropy: 0.3300 - precision: 0.7870 - recall: 0.4756 - val_loss: 0.3570 - val_binary_accuracy: 0.8600 - val_binary_crossentropy: 0.3570 - val_precision: 0.7441 - val_recall: 0.4423 - 597ms/epoch - 3ms/step\n",
            "Epoch 35/80\n",
            "225/225 - 1s - loss: 0.3323 - binary_accuracy: 0.8607 - binary_crossentropy: 0.3323 - precision: 0.7753 - recall: 0.4512 - val_loss: 0.3608 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3608 - val_precision: 0.7167 - val_recall: 0.4704 - 527ms/epoch - 2ms/step\n",
            "Epoch 36/80\n",
            "225/225 - 1s - loss: 0.3312 - binary_accuracy: 0.8654 - binary_crossentropy: 0.3312 - precision: 0.7891 - recall: 0.4688 - val_loss: 0.3511 - val_binary_accuracy: 0.8617 - val_binary_crossentropy: 0.3511 - val_precision: 0.7849 - val_recall: 0.4113 - 617ms/epoch - 3ms/step\n",
            "Epoch 37/80\n",
            "225/225 - 1s - loss: 0.3281 - binary_accuracy: 0.8667 - binary_crossentropy: 0.3281 - precision: 0.8108 - recall: 0.4560 - val_loss: 0.3722 - val_binary_accuracy: 0.8467 - val_binary_crossentropy: 0.3722 - val_precision: 0.6287 - val_recall: 0.5437 - 527ms/epoch - 2ms/step\n",
            "Epoch 38/80\n",
            "225/225 - 1s - loss: 0.3295 - binary_accuracy: 0.8654 - binary_crossentropy: 0.3295 - precision: 0.7845 - recall: 0.4736 - val_loss: 0.3524 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3524 - val_precision: 0.7131 - val_recall: 0.4761 - 515ms/epoch - 2ms/step\n",
            "Epoch 39/80\n",
            "225/225 - 1s - loss: 0.3306 - binary_accuracy: 0.8635 - binary_crossentropy: 0.3306 - precision: 0.7682 - recall: 0.4783 - val_loss: 0.3573 - val_binary_accuracy: 0.8567 - val_binary_crossentropy: 0.3573 - val_precision: 0.7082 - val_recall: 0.4648 - 599ms/epoch - 3ms/step\n",
            "Epoch 40/80\n",
            "225/225 - 1s - loss: 0.3302 - binary_accuracy: 0.8618 - binary_crossentropy: 0.3302 - precision: 0.7742 - recall: 0.4600 - val_loss: 0.3554 - val_binary_accuracy: 0.8578 - val_binary_crossentropy: 0.3554 - val_precision: 0.7324 - val_recall: 0.4394 - 618ms/epoch - 3ms/step\n",
            "Epoch 41/80\n",
            "225/225 - 1s - loss: 0.3293 - binary_accuracy: 0.8674 - binary_crossentropy: 0.3293 - precision: 0.7984 - recall: 0.4722 - val_loss: 0.3628 - val_binary_accuracy: 0.8606 - val_binary_crossentropy: 0.3628 - val_precision: 0.6871 - val_recall: 0.5380 - 523ms/epoch - 2ms/step\n",
            "Epoch 42/80\n",
            "225/225 - 1s - loss: 0.3316 - binary_accuracy: 0.8621 - binary_crossentropy: 0.3316 - precision: 0.7611 - recall: 0.4770 - val_loss: 0.3570 - val_binary_accuracy: 0.8567 - val_binary_crossentropy: 0.3570 - val_precision: 0.6917 - val_recall: 0.4930 - 517ms/epoch - 2ms/step\n",
            "Epoch 43/80\n",
            "225/225 - 1s - loss: 0.3288 - binary_accuracy: 0.8650 - binary_crossentropy: 0.3288 - precision: 0.7800 - recall: 0.4756 - val_loss: 0.3582 - val_binary_accuracy: 0.8572 - val_binary_crossentropy: 0.3582 - val_precision: 0.6750 - val_recall: 0.5324 - 599ms/epoch - 3ms/step\n",
            "Epoch 44/80\n",
            "225/225 - 1s - loss: 0.3243 - binary_accuracy: 0.8661 - binary_crossentropy: 0.3243 - precision: 0.7712 - recall: 0.4932 - val_loss: 0.3861 - val_binary_accuracy: 0.8356 - val_binary_crossentropy: 0.3861 - val_precision: 0.5795 - val_recall: 0.6056 - 625ms/epoch - 3ms/step\n",
            "Epoch 45/80\n",
            "225/225 - 1s - loss: 0.3316 - binary_accuracy: 0.8614 - binary_crossentropy: 0.3316 - precision: 0.7673 - recall: 0.4648 - val_loss: 0.3531 - val_binary_accuracy: 0.8561 - val_binary_crossentropy: 0.3531 - val_precision: 0.6935 - val_recall: 0.4845 - 578ms/epoch - 3ms/step\n",
            "Epoch 46/80\n",
            "225/225 - 1s - loss: 0.3254 - binary_accuracy: 0.8650 - binary_crossentropy: 0.3254 - precision: 0.7851 - recall: 0.4702 - val_loss: 0.3492 - val_binary_accuracy: 0.8633 - val_binary_crossentropy: 0.3492 - val_precision: 0.7280 - val_recall: 0.4901 - 594ms/epoch - 3ms/step\n",
            "Epoch 47/80\n",
            "225/225 - 1s - loss: 0.3257 - binary_accuracy: 0.8667 - binary_crossentropy: 0.3257 - precision: 0.8007 - recall: 0.4654 - val_loss: 0.3485 - val_binary_accuracy: 0.8689 - val_binary_crossentropy: 0.3485 - val_precision: 0.7767 - val_recall: 0.4704 - 586ms/epoch - 3ms/step\n",
            "Epoch 48/80\n",
            "225/225 - 1s - loss: 0.3262 - binary_accuracy: 0.8653 - binary_crossentropy: 0.3262 - precision: 0.7908 - recall: 0.4661 - val_loss: 0.3539 - val_binary_accuracy: 0.8594 - val_binary_crossentropy: 0.3539 - val_precision: 0.7318 - val_recall: 0.4535 - 588ms/epoch - 3ms/step\n",
            "Epoch 49/80\n",
            "225/225 - 1s - loss: 0.3257 - binary_accuracy: 0.8636 - binary_crossentropy: 0.3257 - precision: 0.7757 - recall: 0.4709 - val_loss: 0.3567 - val_binary_accuracy: 0.8550 - val_binary_crossentropy: 0.3567 - val_precision: 0.6703 - val_recall: 0.5211 - 611ms/epoch - 3ms/step\n",
            "Epoch 50/80\n",
            "225/225 - 1s - loss: 0.3237 - binary_accuracy: 0.8643 - binary_crossentropy: 0.3237 - precision: 0.7745 - recall: 0.4770 - val_loss: 0.3581 - val_binary_accuracy: 0.8611 - val_binary_crossentropy: 0.3581 - val_precision: 0.7692 - val_recall: 0.4225 - 590ms/epoch - 3ms/step\n",
            "Epoch 51/80\n",
            "225/225 - 1s - loss: 0.3231 - binary_accuracy: 0.8690 - binary_crossentropy: 0.3231 - precision: 0.7945 - recall: 0.4871 - val_loss: 0.3506 - val_binary_accuracy: 0.8628 - val_binary_crossentropy: 0.3506 - val_precision: 0.7523 - val_recall: 0.4535 - 591ms/epoch - 3ms/step\n",
            "Epoch 52/80\n",
            "225/225 - 1s - loss: 0.3239 - binary_accuracy: 0.8674 - binary_crossentropy: 0.3239 - precision: 0.7891 - recall: 0.4817 - val_loss: 0.3633 - val_binary_accuracy: 0.8572 - val_binary_crossentropy: 0.3633 - val_precision: 0.7112 - val_recall: 0.4648 - 542ms/epoch - 2ms/step\n",
            "Epoch 53/80\n",
            "225/225 - 1s - loss: 0.3205 - binary_accuracy: 0.8675 - binary_crossentropy: 0.3205 - precision: 0.7837 - recall: 0.4885 - val_loss: 0.3761 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3761 - val_precision: 0.7066 - val_recall: 0.4817 - 543ms/epoch - 2ms/step\n",
            "Epoch 54/80\n",
            "225/225 - 1s - loss: 0.3245 - binary_accuracy: 0.8657 - binary_crossentropy: 0.3245 - precision: 0.7856 - recall: 0.4743 - val_loss: 0.3486 - val_binary_accuracy: 0.8611 - val_binary_crossentropy: 0.3486 - val_precision: 0.7160 - val_recall: 0.4901 - 516ms/epoch - 2ms/step\n",
            "Epoch 55/80\n",
            "225/225 - 1s - loss: 0.3189 - binary_accuracy: 0.8686 - binary_crossentropy: 0.3189 - precision: 0.7874 - recall: 0.4919 - val_loss: 0.3601 - val_binary_accuracy: 0.8578 - val_binary_crossentropy: 0.3601 - val_precision: 0.7004 - val_recall: 0.4873 - 546ms/epoch - 2ms/step\n",
            "Epoch 56/80\n",
            "225/225 - 1s - loss: 0.3218 - binary_accuracy: 0.8664 - binary_crossentropy: 0.3218 - precision: 0.7881 - recall: 0.4763 - val_loss: 0.3547 - val_binary_accuracy: 0.8650 - val_binary_crossentropy: 0.3547 - val_precision: 0.7276 - val_recall: 0.5042 - 579ms/epoch - 3ms/step\n",
            "Epoch 57/80\n",
            "225/225 - 1s - loss: 0.3203 - binary_accuracy: 0.8665 - binary_crossentropy: 0.3203 - precision: 0.7827 - recall: 0.4831 - val_loss: 0.3528 - val_binary_accuracy: 0.8656 - val_binary_crossentropy: 0.3528 - val_precision: 0.7446 - val_recall: 0.4845 - 606ms/epoch - 3ms/step\n",
            "Epoch 58/80\n",
            "225/225 - 1s - loss: 0.3186 - binary_accuracy: 0.8690 - binary_crossentropy: 0.3186 - precision: 0.7925 - recall: 0.4892 - val_loss: 0.3711 - val_binary_accuracy: 0.8544 - val_binary_crossentropy: 0.3711 - val_precision: 0.6566 - val_recall: 0.5493 - 606ms/epoch - 3ms/step\n",
            "Epoch 59/80\n",
            "225/225 - 1s - loss: 0.3227 - binary_accuracy: 0.8653 - binary_crossentropy: 0.3227 - precision: 0.7768 - recall: 0.4810 - val_loss: 0.3642 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3642 - val_precision: 0.6797 - val_recall: 0.5380 - 525ms/epoch - 2ms/step\n",
            "Epoch 60/80\n",
            "225/225 - 1s - loss: 0.3193 - binary_accuracy: 0.8660 - binary_crossentropy: 0.3193 - precision: 0.7727 - recall: 0.4905 - val_loss: 0.3584 - val_binary_accuracy: 0.8567 - val_binary_crossentropy: 0.3584 - val_precision: 0.6873 - val_recall: 0.5014 - 554ms/epoch - 2ms/step\n",
            "Epoch 61/80\n",
            "225/225 - 1s - loss: 0.3206 - binary_accuracy: 0.8672 - binary_crossentropy: 0.3206 - precision: 0.7778 - recall: 0.4932 - val_loss: 0.3577 - val_binary_accuracy: 0.8567 - val_binary_crossentropy: 0.3577 - val_precision: 0.6873 - val_recall: 0.5014 - 592ms/epoch - 3ms/step\n",
            "Epoch 62/80\n",
            "225/225 - 1s - loss: 0.3184 - binary_accuracy: 0.8683 - binary_crossentropy: 0.3184 - precision: 0.7876 - recall: 0.4898 - val_loss: 0.3582 - val_binary_accuracy: 0.8544 - val_binary_crossentropy: 0.3582 - val_precision: 0.6838 - val_recall: 0.4873 - 633ms/epoch - 3ms/step\n",
            "Epoch 63/80\n",
            "225/225 - 1s - loss: 0.3172 - binary_accuracy: 0.8692 - binary_crossentropy: 0.3172 - precision: 0.7960 - recall: 0.4864 - val_loss: 0.3586 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3586 - val_precision: 0.7174 - val_recall: 0.4648 - 616ms/epoch - 3ms/step\n",
            "Epoch 64/80\n",
            "225/225 - 1s - loss: 0.3200 - binary_accuracy: 0.8693 - binary_crossentropy: 0.3200 - precision: 0.7943 - recall: 0.4892 - val_loss: 0.3669 - val_binary_accuracy: 0.8600 - val_binary_crossentropy: 0.3669 - val_precision: 0.7102 - val_recall: 0.4901 - 600ms/epoch - 3ms/step\n",
            "Epoch 65/80\n",
            "225/225 - 1s - loss: 0.3161 - binary_accuracy: 0.8672 - binary_crossentropy: 0.3161 - precision: 0.7857 - recall: 0.4844 - val_loss: 0.3670 - val_binary_accuracy: 0.8544 - val_binary_crossentropy: 0.3670 - val_precision: 0.6742 - val_recall: 0.5070 - 574ms/epoch - 3ms/step\n",
            "Epoch 66/80\n",
            "225/225 - 1s - loss: 0.3156 - binary_accuracy: 0.8701 - binary_crossentropy: 0.3156 - precision: 0.7875 - recall: 0.5020 - val_loss: 0.3602 - val_binary_accuracy: 0.8622 - val_binary_crossentropy: 0.3602 - val_precision: 0.7488 - val_recall: 0.4535 - 637ms/epoch - 3ms/step\n",
            "Epoch 67/80\n",
            "225/225 - 1s - loss: 0.3140 - binary_accuracy: 0.8706 - binary_crossentropy: 0.3140 - precision: 0.8029 - recall: 0.4885 - val_loss: 0.3520 - val_binary_accuracy: 0.8628 - val_binary_crossentropy: 0.3520 - val_precision: 0.7308 - val_recall: 0.4817 - 562ms/epoch - 2ms/step\n",
            "Epoch 68/80\n",
            "225/225 - 1s - loss: 0.3112 - binary_accuracy: 0.8707 - binary_crossentropy: 0.3112 - precision: 0.7871 - recall: 0.5061 - val_loss: 0.3762 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3762 - val_precision: 0.6812 - val_recall: 0.5296 - 601ms/epoch - 3ms/step\n",
            "Epoch 69/80\n",
            "225/225 - 1s - loss: 0.3137 - binary_accuracy: 0.8711 - binary_crossentropy: 0.3137 - precision: 0.7825 - recall: 0.5142 - val_loss: 0.3652 - val_binary_accuracy: 0.8589 - val_binary_crossentropy: 0.3652 - val_precision: 0.7760 - val_recall: 0.4000 - 604ms/epoch - 3ms/step\n",
            "Epoch 70/80\n",
            "225/225 - 1s - loss: 0.3142 - binary_accuracy: 0.8714 - binary_crossentropy: 0.3142 - precision: 0.8022 - recall: 0.4946 - val_loss: 0.3747 - val_binary_accuracy: 0.8572 - val_binary_crossentropy: 0.3747 - val_precision: 0.6763 - val_recall: 0.5296 - 608ms/epoch - 3ms/step\n",
            "Epoch 71/80\n",
            "225/225 - 1s - loss: 0.3159 - binary_accuracy: 0.8697 - binary_crossentropy: 0.3159 - precision: 0.7832 - recall: 0.5041 - val_loss: 0.3626 - val_binary_accuracy: 0.8639 - val_binary_crossentropy: 0.3626 - val_precision: 0.7022 - val_recall: 0.5380 - 544ms/epoch - 2ms/step\n",
            "Epoch 72/80\n",
            "225/225 - 1s - loss: 0.3115 - binary_accuracy: 0.8706 - binary_crossentropy: 0.3115 - precision: 0.7816 - recall: 0.5115 - val_loss: 0.3770 - val_binary_accuracy: 0.8539 - val_binary_crossentropy: 0.3770 - val_precision: 0.6679 - val_recall: 0.5155 - 560ms/epoch - 2ms/step\n",
            "Epoch 73/80\n",
            "225/225 - 1s - loss: 0.3143 - binary_accuracy: 0.8662 - binary_crossentropy: 0.3143 - precision: 0.7647 - recall: 0.5020 - val_loss: 0.3808 - val_binary_accuracy: 0.8628 - val_binary_crossentropy: 0.3808 - val_precision: 0.8034 - val_recall: 0.4028 - 588ms/epoch - 3ms/step\n",
            "Epoch 74/80\n",
            "225/225 - 1s - loss: 0.3151 - binary_accuracy: 0.8674 - binary_crossentropy: 0.3151 - precision: 0.7822 - recall: 0.4892 - val_loss: 0.3610 - val_binary_accuracy: 0.8567 - val_binary_crossentropy: 0.3610 - val_precision: 0.6858 - val_recall: 0.5042 - 543ms/epoch - 2ms/step\n",
            "Epoch 75/80\n",
            "225/225 - 1s - loss: 0.3099 - binary_accuracy: 0.8707 - binary_crossentropy: 0.3099 - precision: 0.7836 - recall: 0.5102 - val_loss: 0.3702 - val_binary_accuracy: 0.8578 - val_binary_crossentropy: 0.3702 - val_precision: 0.7037 - val_recall: 0.4817 - 532ms/epoch - 2ms/step\n",
            "Epoch 76/80\n",
            "225/225 - 1s - loss: 0.3103 - binary_accuracy: 0.8690 - binary_crossentropy: 0.3103 - precision: 0.7802 - recall: 0.5027 - val_loss: 0.3808 - val_binary_accuracy: 0.8522 - val_binary_crossentropy: 0.3808 - val_precision: 0.6561 - val_recall: 0.5268 - 603ms/epoch - 3ms/step\n",
            "Epoch 77/80\n",
            "225/225 - 1s - loss: 0.3100 - binary_accuracy: 0.8696 - binary_crossentropy: 0.3100 - precision: 0.7847 - recall: 0.5014 - val_loss: 0.3833 - val_binary_accuracy: 0.8522 - val_binary_crossentropy: 0.3833 - val_precision: 0.6642 - val_recall: 0.5070 - 603ms/epoch - 3ms/step\n",
            "Epoch 78/80\n",
            "225/225 - 1s - loss: 0.3102 - binary_accuracy: 0.8710 - binary_crossentropy: 0.3102 - precision: 0.7996 - recall: 0.4946 - val_loss: 0.3600 - val_binary_accuracy: 0.8661 - val_binary_crossentropy: 0.3600 - val_precision: 0.7336 - val_recall: 0.5042 - 599ms/epoch - 3ms/step\n",
            "Epoch 79/80\n",
            "225/225 - 1s - loss: 0.3106 - binary_accuracy: 0.8696 - binary_crossentropy: 0.3106 - precision: 0.7890 - recall: 0.4966 - val_loss: 0.3885 - val_binary_accuracy: 0.8528 - val_binary_crossentropy: 0.3885 - val_precision: 0.6552 - val_recall: 0.5352 - 593ms/epoch - 3ms/step\n",
            "Epoch 80/80\n",
            "225/225 - 1s - loss: 0.3078 - binary_accuracy: 0.8743 - binary_crossentropy: 0.3078 - precision: 0.7922 - recall: 0.5244 - val_loss: 0.3687 - val_binary_accuracy: 0.8583 - val_binary_crossentropy: 0.3687 - val_precision: 0.7381 - val_recall: 0.4366 - 631ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa96bcd0dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados do modelo"
      ],
      "metadata": {
        "id": "HbWZXW2JIABv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc, binary_crossentropy, precision, recall= model.evaluate(X_test_numpy, y_test_numpy)\n",
        "print(\"Test Accuracy: \"+ str(acc))\n",
        "print(\"Test Precision: \" + str(precision))\n",
        "print('Test Recall: '+ str(recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeYeADbEH8wX",
        "outputId": "8261e7d2-ddc3-4b90-ad34-2a44785f72c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 2ms/step - loss: 0.3687 - binary_accuracy: 0.8583 - binary_crossentropy: 0.3687 - precision: 0.7381 - recall: 0.4366\n",
            "Test Accuracy: 0.8583333492279053\n",
            "Test Precision: 0.738095223903656\n",
            "Test Recall: 0.43661972880363464\n",
            "Test F1: 0.5486725707361845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "b= np.array( [0.7] )\n",
        "print( np.round(b) )\n",
        "\n",
        "y_predicted= model.predict(X_test_numpy)\n",
        "y_predicted\n",
        "\n",
        "rounded_y_predicted= np.round(y_predicted)\n",
        "print( classification_report(y_test_numpy, rounded_y_predicted) ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWRhP_wbIB-3",
        "outputId": "37b7f96d-dbb2-4b91-a5fb-f2c30aea7454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.]\n",
            "57/57 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.96      0.92      1445\n",
            "         1.0       0.74      0.44      0.55       355\n",
            "\n",
            "    accuracy                           0.86      1800\n",
            "   macro avg       0.81      0.70      0.73      1800\n",
            "weighted avg       0.85      0.86      0.84      1800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt = np.round(y_predicted)\n"
      ],
      "metadata": {
        "id": "JR4j1xZrY145"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Array com as previsões."
      ],
      "metadata": {
        "id": "7FzVt2t1_57Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt[1:600]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuuUczDYS0dn",
        "outputId": "f1a57b31-268f-4c72-ee40-ef8bc3fbf802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}